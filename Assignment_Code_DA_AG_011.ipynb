{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "                    Logistic Regression\n",
        "\n",
        "  \n",
        "1.What is Logistic Regression, and how does it differ from Linear\n",
        "Regression?\n",
        "\n",
        "- Logistic Regression is a statistical model used for binary classification problems, where the outcome is categorical and can have only two possible values (e.g., yes/no, true/false, spam/not spam). It uses a logistic function (sigmoid function) to model the probability of the outcome belonging to a particular category.\n",
        "\n",
        "Linear Regression, on the other hand, is used for predicting a continuous outcome variable based on one or more predictor variables. It assumes a linear relationship between the input variables and the output variable.\n",
        "\n",
        "key differences:\n",
        "\n",
        "Output: Logistic Regression predicts a probability (between 0 and 1), while Linear Regression predicts a continuous value.\n",
        "\n",
        "Relationship: Logistic Regression uses a sigmoid function to model a non-linear relationship between input and output, while Linear Regression assumes a linear relationship.\n",
        "\n",
        "Loss Function: Logistic Regression typically uses the log loss (or cross-entropy loss) function, while Linear Regression uses the mean squared error (MSE) loss function.\n",
        "\n",
        "Applications: Logistic Regression is used for classification tasks, while Linear Regression is used for regression tasks."
      ],
      "metadata": {
        "id": "WiTPZxl7KJyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Explain the role of the Sigmoid function in Logistic Regression?\n",
        "\n",
        "- The sigmoid function, also known as the logistic function, plays a crucial role in Logistic Regression. It is a mathematical function that takes any real-valued number and maps it to a value between 0 and 1. In Logistic Regression, the sigmoid function is used to transform the linear output of the model into a probability.\n",
        "\n",
        "Specifically, the linear combination of the input features and their corresponding weights (i.e., the output of the linear part of the model) is passed through the sigmoid function. The output of the sigmoid function is then interpreted as the probability that the instance belongs to the positive class (usually denoted as 1).\n",
        "\n",
        "The formula for the sigmoid function is:\n",
        "\n",
        "$$ \\sigma(z) = \\frac{1}{1 + e^{-z}} $$\n",
        "\n",
        "where $z$ is the linear output of the model.\n",
        "\n",
        "The sigmoid function has several desirable properties for this purpose:\n",
        "\n",
        "- It is monotonic and differentiable, which is important for optimization algorithms like gradient descent.\n",
        "- It squashes the output to a range between 0 and 1, which can be interpreted as a probability.\n",
        "- It has a clear interpretation: values closer to 1 indicate a higher probability of belonging to the positive class, while values closer to 0 indicate a higher probability of belonging to the negative class."
      ],
      "metadata": {
        "id": "LIotEyIwLi5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.What is Regularization in Logistic Regression and why is it needed?\n",
        "\n",
        "- Regularization is a technique used in Logistic Regression (and other machine learning models) to prevent overfitting. Overfitting occurs when a model learns the training data too well, including the noise and random fluctuations, which leads to poor performance on unseen data.\n",
        "In Logistic Regression, overfitting can happen when the model has too many features or when the features are highly correlated. Regularization addresses this by adding a penalty term to the loss function that the model tries to minimize during training. This penalty term discourages the model from assigning excessively large weights to the features.\n",
        "\n",
        "There are two common types of regularization used in Logistic Regression:\n",
        "\n",
        "L1 Regularization (Lasso Regularization): Adds a penalty proportional to the absolute value of the weights. This type of regularization can lead to sparse models, where some feature weights become exactly zero, effectively performing feature selection.\n",
        "\n",
        "L2 Regularization (Ridge Regularization): Adds a penalty proportional to the square of the weights. This type of regularization shrinks the weights towards zero but does not necessarily make them exactly zero.\n",
        "\n",
        "Need Of regularization->\n",
        "Preventing Overfitting:\n",
        "The primary reason for using regularization is to prevent the model from overfitting the training data, which improves its generalization ability to unseen data.\n",
        "Handling Multicollinearity: Regularization can help in situations where there is high correlation between features\n",
        "\n",
        "(multicollinearity). It can shrink the weights of correlated features, making the model more stable.\n",
        "\n",
        "Improving Model Interpretability: L1 regularization, by setting some weights to zero, can help in identifying the most important features, leading to a more interpretable model.\n",
        "\n",
        "Reducing Model Complexity: By discouraging large weights, regularization effectively reduces the complexity of the model, making it less sensitive to small variations in the training data.\n"
      ],
      "metadata": {
        "id": "6lPGxIL8Mcqe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.What are some common evaluation metrics for classification models, and why are they important?\n",
        "\n",
        "- Here are some common evaluation metrics:\n",
        "\n",
        "Accuracy:\n",
        "The proportion of correctly classified instances out of the total number of instances.\n",
        "Importance: Provides a general overview of the model's performance. However, it can be misleading in cases of imbalanced datasets where one class is significantly more prevalent than others.\n",
        "\n",
        "Precision:\n",
        "The proportion of true positive predictions among all positive predictions.\n",
        "Importance: Useful when the cost of false positives is high. It measures the model's ability to avoid incorrectly classifying negative instances as positive.\n",
        "\n",
        "Recall (Sensitivity or True Positive Rate):\n",
        "The proportion of true positive predictions among all actual positive instances.\n",
        "Importance: Useful when the cost of false negatives is high. It measures the model's ability to find all positive instances.\n",
        "\n",
        "F1-Score:\n",
        "The harmonic mean of precision and recall.\n",
        "Importance: Provides a balance between precision and recall, especially useful when there is an uneven class distribution.\n",
        "\n",
        "Confusion Matrix:\n",
        "A table that summarizes the performance of a classification model on a set of test data. It shows the number of true positives, true negatives, false positives, and false negatives.\n",
        "Importance: Provides a detailed breakdown of the model's predictions and helps in understanding where the model is making errors.\n",
        "\n",
        "AUC (Area Under the ROC Curve):\n",
        "The area under the Receiver Operating Characteristic (ROC) curve, which plots the true positive rate against the false positive rate at various threshold settings.\n",
        "Importance: Measures the model's ability to distinguish between positive and negative classes. A higher AUC indicates better performance.\n",
        "\n",
        "Log Loss (Cross-Entropy Loss):\n",
        "A metric that penalizes incorrect predictions based on the predicted probability. It measures the performance of a classification model whose output is a probability value between 0 and 1.\n",
        "\n",
        "Significance: Useful in evaluating the confidence of the model's predictions. Lower log loss indicates better performance.\n",
        "\n",
        "Why are they important?\n",
        "\n",
        "Understanding Performance: Metrics provide a quantitative way to measure how well a model is performing on a given task.\n",
        "\n",
        "Comparing Models: Different models can be compared based on their performance on various metrics to choose the best model for a specific problem.\n",
        "\n",
        "Identifying Model Weaknesses: Analyzing different metrics can reveal specific areas where the model is struggling (e.g., high false positives or false negatives).\n",
        "\n",
        "Guiding Model Improvement: Understanding the metrics can help in guiding the process of improving the model, such as tuning hyperparameters or selecting different features.\n",
        "\n",
        "Communicating Results: Metrics provide a standardized way to communicate the performance of a model to stakeholders.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lBfSHN8_bHWc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.Write a Python program that loads a CSV file into a Pandas DataFrame, splits into train/test sets, trains a Logistic Regression model, and prints its accuracy."
      ],
      "metadata": {
        "id": "m1JR9sg8eLYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as snp\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.datasets import load_iris\n",
        "data=load_iris()\n",
        "data\n",
        "data.feature_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTnY_Ao3gknr",
        "outputId": "44b4a22b-92eb-4bb2-dc95-611e5025f0cd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sepal length (cm)',\n",
              " 'sepal width (cm)',\n",
              " 'petal length (cm)',\n",
              " 'petal width (cm)']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(data.data,columns=data.feature_names)\n",
        "df['target']=data.target\n",
        "df.head()\n",
        "df.tail()\n",
        "df.sample(1)\n",
        "df.target.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fic1dFN40mBR",
        "outputId": "a21342ef-6ba2-4c6a-b3d3-611bcc33843e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for binary classification only two classes are required\n",
        "df=df[df.target!=2]\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "YI1Uxk8I14e4",
        "outputId": "6d385f7a-88f7-4dfe-b3df-75268ed32b02"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0                 5.1               3.5                1.4               0.2   \n",
              "1                 4.9               3.0                1.4               0.2   \n",
              "2                 4.7               3.2                1.3               0.2   \n",
              "3                 4.6               3.1                1.5               0.2   \n",
              "4                 5.0               3.6                1.4               0.2   \n",
              "..                ...               ...                ...               ...   \n",
              "95                5.7               3.0                4.2               1.2   \n",
              "96                5.7               2.9                4.2               1.3   \n",
              "97                6.2               2.9                4.3               1.3   \n",
              "98                5.1               2.5                3.0               1.1   \n",
              "99                5.7               2.8                4.1               1.3   \n",
              "\n",
              "    target  \n",
              "0        0  \n",
              "1        0  \n",
              "2        0  \n",
              "3        0  \n",
              "4        0  \n",
              "..     ...  \n",
              "95       1  \n",
              "96       1  \n",
              "97       1  \n",
              "98       1  \n",
              "99       1  \n",
              "\n",
              "[100 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a52b5c04-f471-4301-9f1b-8209870b92cf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>5.7</td>\n",
              "      <td>2.9</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>6.2</td>\n",
              "      <td>2.9</td>\n",
              "      <td>4.3</td>\n",
              "      <td>1.3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>5.1</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>5.7</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1.3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a52b5c04-f471-4301-9f1b-8209870b92cf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a52b5c04-f471-4301-9f1b-8209870b92cf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a52b5c04-f471-4301-9f1b-8209870b92cf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1a2ed0c3-7690-44dd-b21c-2c5d9ce171b3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1a2ed0c3-7690-44dd-b21c-2c5d9ce171b3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1a2ed0c3-7690-44dd-b21c-2c5d9ce171b3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_fbe24b06-1a37-4240-a8ab-a493eba192d8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fbe24b06-1a37-4240-a8ab-a493eba192d8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"sepal length (cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6416983463254117,\n        \"min\": 4.3,\n        \"max\": 7.0,\n        \"num_unique_values\": 28,\n        \"samples\": [\n          5.8,\n          6.7,\n          4.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sepal width (cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.47873887359489514,\n        \"min\": 2.0,\n        \"max\": 4.4,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          2.3,\n          4.0,\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal length (cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4495485190537465,\n        \"min\": 1.0,\n        \"max\": 5.1,\n        \"num_unique_values\": 28,\n        \"samples\": [\n          4.7,\n          3.7,\n          1.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal width (cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5651530587354014,\n        \"min\": 0.1,\n        \"max\": 1.8,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          1.6,\n          1.1,\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.target.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMM4DkG63NQM",
        "outputId": "d4bb7ed3-3795-42a7-c2a6-aea5039dd9d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=df.iloc[:,:-1]\n",
        "x\n",
        "y=df.iloc[:,-1]\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "VuJJjGLo3yrz",
        "outputId": "31d4c864-5229-4822-98b7-5b7b27e19b4b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0\n",
              "1     0\n",
              "2     0\n",
              "3     0\n",
              "4     0\n",
              "     ..\n",
              "95    1\n",
              "96    1\n",
              "97    1\n",
              "98    1\n",
              "99    1\n",
              "Name: target, Length: 100, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split #Train test split process\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bNUXsBG39vp",
        "outputId": "8f91e459-c2ed-4a86-f483-66c948a91d8c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((80, 4), (20, 4), (80,), (20,))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier=LogisticRegression()\n",
        "classifier.fit(x_train,y_train)\n",
        "classifier\n",
        "y_pred=classifier.predict(x_test)\n",
        "y_pred\n"
      ],
      "metadata": {
        "id": "2m_54pzTFl3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3901796-83b9-4dc3-b8b8-6dabf389f6a0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_proba=classifier.predict_proba(x_test)\n",
        "classifier_proba"
      ],
      "metadata": {
        "id": "8oFTCdfzOSGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfed6327-a1f7-4757-dcaa-6fdac5e1c893"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.04043262, 0.95956738],\n",
              "       [0.01046123, 0.98953877],\n",
              "       [0.98706759, 0.01293241],\n",
              "       [0.05440516, 0.94559484],\n",
              "       [0.1383348 , 0.8616652 ],\n",
              "       [0.97966131, 0.02033869],\n",
              "       [0.98204504, 0.01795496],\n",
              "       [0.03292232, 0.96707768],\n",
              "       [0.03380573, 0.96619427],\n",
              "       [0.00850516, 0.99149484],\n",
              "       [0.02466034, 0.97533966],\n",
              "       [0.97515854, 0.02484146],\n",
              "       [0.00517837, 0.99482163],\n",
              "       [0.00238366, 0.99761634],\n",
              "       [0.0077453 , 0.9922547 ],\n",
              "       [0.98619342, 0.01380658],\n",
              "       [0.96597536, 0.03402464],\n",
              "       [0.94907826, 0.05092174],\n",
              "       [0.00735493, 0.99264507],\n",
              "       [0.97742977, 0.02257023]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Matric Evaluation\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "print(f\"\\n Accuracy Score:\\n\")\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(f\"\\n Confusion Matrix:\\n\")\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(f\"\\n Classification Report:\\n\")\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "5qYdgRCuPVxL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5404f60a-eff2-4c1f-8511-d94323e595ae"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Accuracy Score:\n",
            "\n",
            "1.0\n",
            "\n",
            " Confusion Matrix:\n",
            "\n",
            "[[ 8  0]\n",
            " [ 0 12]]\n",
            "\n",
            " Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         8\n",
            "           1       1.00      1.00      1.00        12\n",
            "\n",
            "    accuracy                           1.00        20\n",
            "   macro avg       1.00      1.00      1.00        20\n",
            "weighted avg       1.00      1.00      1.00        20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.Write a Python program to train a Logistic Regression model using L2 regularization (Ridge) and print the model coefficients and accuracy.\n"
      ],
      "metadata": {
        "id": "z_UMnJSkhX2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Train a Logistic Regression model with L2 regularization\n",
        "# C is the inverse of regularization strength; smaller values specify stronger regularization.\n",
        "classifier_l2 = LogisticRegression(penalty='l2', C=1.0)\n",
        "classifier_l2.fit(x_train, y_train)\n",
        "\n",
        "# Print the model coefficients\n",
        "print(\"\\n Model Coefficients:\\n\")\n",
        "print(classifier_l2.coef_)\n",
        "print(\"\\n Model Intercept:\\n\")\n",
        "print(classifier_l2.intercept_)\n",
        "\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_l2 = classifier_l2.predict(x_test)\n",
        "\n",
        "# Print the accuracy\n",
        "accuracy_l2 = accuracy_score(y_test, y_pred_l2)\n",
        "print(f\"\\nAccuracy with L2 regularization: {accuracy_l2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21jck_1mfoLL",
        "outputId": "dc2fab48-21a8-4ec6-9241-83598c674584"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Model Coefficients:\n",
            "\n",
            "[[ 0.46100411 -0.78836575  2.18624929  0.92865666]]\n",
            "\n",
            " Model Intercept:\n",
            "\n",
            "[-6.80586873]\n",
            "\n",
            "Accuracy with L2 regularization: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr' and print the classification report."
      ],
      "metadata": {
        "id": "7x5kDc1PjAt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Use the full dataset for multiclass classification\n",
        "# Reload the data to include all three classes\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "df_multi = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df_multi['target'] = data.target\n",
        "\n",
        "x_multi = df_multi.iloc[:, :-1]\n",
        "y_multi = df_multi.iloc[:, -1]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "x_train_multi, x_test_multi, y_train_multi, y_test_multi = train_test_split(x_multi, y_multi, test_size=0.2, random_state=1)\n",
        "\n",
        "# Train a Logistic Regression model with multi_class='ovr'\n",
        "classifier_ovr = LogisticRegression(multi_class='ovr', solver='liblinear') # 'liblinear' solver is suitable for 'ovr'\n",
        "classifier_ovr.fit(x_train_multi, y_train_multi)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_ovr = classifier_ovr.predict(x_test_multi)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report (multi_class='ovr'):\\n\")\n",
        "print(classification_report(y_test_multi, y_pred_ovr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZGpeHduiYzz",
        "outputId": "afb9ab55-450d-4b0b-f17d-f5c7182b067a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report (multi_class='ovr'):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        11\n",
            "           1       1.00      0.62      0.76        13\n",
            "           2       0.55      1.00      0.71         6\n",
            "\n",
            "    accuracy                           0.83        30\n",
            "   macro avg       0.85      0.87      0.82        30\n",
            "weighted avg       0.91      0.83      0.84        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.Write a Python program to apply GridSearchCV to tune C and penalty hyperparameters for Logistic Regression and print the best parameters and validation\n",
        "accuracy."
      ],
      "metadata": {
        "id": "v5nU8RMrkKxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "# Use a solver that supports both l1 and l2 penalties, like 'liblinear' or 'saga'\n",
        "# For 'l1' penalty, 'liblinear' is generally faster for small datasets\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "\n",
        "# Create GridSearchCV object\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the grid search to the data\n",
        "# Using the binary classification data (x, y) from previous steps\n",
        "grid_search.fit(x, y)\n",
        "\n",
        "# Print the best parameters and best score (validation accuracy)\n",
        "print(\"\\nBest Parameters:\\n\")\n",
        "print(grid_search.best_params_)\n",
        "print(\"\\nBest Validation Accuracy:\\n\")\n",
        "print(grid_search.best_score_)\n",
        "\n",
        "# You can also evaluate the best model on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_tuned = best_model.predict(x_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_tuned)\n",
        "print(f\"\\nTest Accuracy with best parameters: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE-oaC9wkRy0",
        "outputId": "ea92d528-d269-43b2-d6ad-065f45767cdb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Parameters:\n",
            "\n",
            "{'C': 0.01, 'penalty': 'l2'}\n",
            "\n",
            "Best Validation Accuracy:\n",
            "\n",
            "1.0\n",
            "\n",
            "Test Accuracy with best parameters: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.Write a Python program to standardize the features before training Logistic Regression and compare the model's accuracy with and without scaling."
      ],
      "metadata": {
        "id": "Nu4-2WKLkeno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Use the binary classification data (x, y)\n",
        "# Split data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
        "\n",
        "# --- Model without scaling ---\n",
        "print(\"\\n--- Model without Scaling ---\")\n",
        "# Train a Logistic Regression model without scaling\n",
        "model_no_scale = LogisticRegression()\n",
        "model_no_scale.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate\n",
        "y_pred_no_scale = model_no_scale.predict(x_test)\n",
        "accuracy_no_scale = accuracy_score(y_test, y_pred_no_scale)\n",
        "print(f\"Accuracy without scaling: {accuracy_no_scale}\")\n",
        "\n",
        "# --- Model with scaling ---\n",
        "print(\"\\n--- Model with Scaling ---\")\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform both training and testing data\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "# Train a Logistic Regression model with scaled data\n",
        "model_scaled = LogisticRegression()\n",
        "model_scaled.fit(x_train_scaled, y_train)\n",
        "\n",
        "# Make predictions and evaluate\n",
        "y_pred_scaled = model_scaled.predict(x_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "print(f\"Accuracy with scaling: {accuracy_scaled}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuOccbVHkrXM",
        "outputId": "2af5293b-103b-4021-88ff-1151050ba00a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model without Scaling ---\n",
            "Accuracy without scaling: 1.0\n",
            "\n",
            "--- Model with Scaling ---\n",
            "Accuracy with scaling: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.Imagine you are working at an e-commerce company that wants to\n",
        "predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach you’d take to build a Logistic Regression model — including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case.\n",
        "\n",
        "- Breakdown of the approach :\n",
        "\n",
        "1. Data Handling:\n",
        "\n",
        "Understand the Data: Thoroughly explore the dataset to understand the features available (e.g., customer demographics, purchase history, website activity, previous campaign interactions) and the target variable (customer response: 1 for responded, 0 for not responded). Identify missing values, outliers, and data types.\n",
        "Feature Engineering: Create new features that might be more informative for the model. For example, you could calculate metrics like:\n",
        "Time since last purchase\n",
        "Number of purchases in the last year\n",
        "Average order value\n",
        "Frequency of website visits\n",
        "Interaction with previous marketing materials\n",
        "Handle Categorical Features: Encode categorical features using techniques like one-hot encoding or dummy encoding.\n",
        "2. Feature Scaling:\n",
        "\n",
        "Standardization or Normalization: Logistic Regression is sensitive to the scale of features. Standardize (using StandardScaler) or normalize (using MinMaxScaler) the numerical features. It's generally recommended to fit the scaler on the training data and then transform both the training and testing data to prevent data leakage.\n",
        "3. Balancing Classes:\n",
        "\n",
        "Given the significant class imbalance (only 5% response rate), simply training the model on the raw data will likely lead to a model that predicts the majority class (no response) most of the time, resulting in high accuracy but poor performance in identifying the responders. To address this:\n",
        "\n",
        "Choose an Appropriate Technique:\n",
        "Oversampling the Minority Class: Techniques like SMOTE (Synthetic Minority Over-sampling Technique) create synthetic samples of the minority class to increase its representation.\n",
        "Undersampling the Majority Class: This involves randomly removing samples from the majority class. However, this can lead to loss of valuable information.\n",
        "Combination of Oversampling and Undersampling: Using techniques like SMOTE followed by Tomek links or Edited Nearest Neighbors.\n",
        "Implementation: Apply the chosen balancing technique only to the training data. Do not balance the test set, as it should represent the real-world imbalanced distribution.\n",
        "4. Hyperparameter Tuning:\n",
        "\n",
        "Identify Important Hyperparameters: For Logistic Regression, key hyperparameters to tune include:\n",
        "C: Inverse of regularization strength. Smaller values mean stronger regularization.\n",
        "penalty: Specifies the norm used in the penalization ('l1' or 'l2'). 'l1' can lead to sparser models (feature selection).\n",
        "solver: Algorithm to use for optimization (e.g., 'liblinear', 'saga', 'lbfgs'). Choose a solver that supports the chosen penalty.\n",
        "Use Cross-Validation: Employ techniques like GridSearchCV or RandomizedSearchCV with cross-validation on the balanced training data to find the best combination of hyperparameters.\n",
        "Specify Appropriate Scoring: When using GridSearchCV or RandomizedSearchCV, use evaluation metrics that are suitable for imbalanced datasets, such as:\n",
        "F1-score\n",
        "Precision-Recall AUC\n",
        "Area Under the ROC Curve (AUC) - while less sensitive to imbalance than accuracy, still useful.\n",
        "5. Evaluating the Model:\n",
        "\n",
        "Since accuracy is not a reliable metric for imbalanced datasets, focus on other evaluation metrics:\n",
        "\n",
        "Confusion Matrix: Analyze the confusion matrix to understand the number of true positives (correctly identified responders), false positives (incorrectly identified responders), true negatives (correctly identified non-responders), and false negatives (incorrectly identified non-responders).\n",
        "Precision and Recall:\n",
        "Precision: The proportion of actual responders among those predicted as responders. Important if the cost of contacting a non-responder is high.\n",
        "Recall: The proportion of predicted responders among actual responders. Important if you want to maximize the number of responders you reach, even if it means contacting some non-responders.\n",
        "F1-Score: The harmonic mean of precision and recall, providing a balanced measure.\n",
        "AUC-ROC and AUC-PR:\n",
        "AUC-ROC: Measures the ability of the model to distinguish between the two classes.\n",
        "AUC-PR (Area Under the Precision-Recall Curve): Particularly useful for imbalanced datasets as it focuses on the performance of the model on the minority class.\n",
        "Classification Report: Use sklearn.metrics.classification_report to get a summary of precision, recall, F1-score, and support for each class.\n",
        "Real-World Business Use Case Considerations:\n",
        "\n",
        "Define the Objective: Clearly define what \"successful\" means for the marketing campaign. Is it maximizing the number of responders (high recall) or minimizing the cost of contacting non-responders (high precision)? This will guide your choice of evaluation metrics and potentially the balancing technique.\n",
        "Thresholding: The default threshold for Logistic Regression is 0.5. For imbalanced datasets, you might need to adjust this threshold to optimize for precision or recall based on the business objective.\n",
        "Business Impact: Evaluate the model's performance in terms of business impact. For example, what is the expected return on investment (ROI) based on the model's predictions?\n",
        "A/B Testing: Once you have a trained model, it's crucial to conduct A/B testing to compare the performance of the campaign targeting customers identified by the model versus a control group.\n",
        "Model Monitoring: Continuously monitor the model's performance in production as customer behavior and data patterns can change over time. Retrain the model periodically with new data.\n"
      ],
      "metadata": {
        "id": "7ZR5kCfalhFo"
      }
    }
  ]
}